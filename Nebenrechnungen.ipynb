{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "\n",
    "n = 3\n",
    "\n",
    "transformations = [\n",
    "    lambda x: x,\n",
    "    lambda x: np.fliplr(x),\n",
    "    lambda x: np.flipud(x),\n",
    "    lambda x: np.flipud(np.fliplr(x)),\n",
    "    lambda x: np.transpose(x),\n",
    "    lambda x: np.fliplr(np.transpose(x)),\n",
    "    lambda x: np.flipud(np.transpose(x)),\n",
    "    lambda x: np.flipud(np.fliplr(np.transpose(x))),\n",
    "]\n",
    "\n",
    "inverse_transformations = [\n",
    "    lambda x: x,\n",
    "    lambda x: np.fliplr(x),\n",
    "    lambda x: np.flipud(x),\n",
    "    lambda x: np.fliplr(np.flipud(x)),\n",
    "    lambda x: np.transpose(x),\n",
    "    lambda x: np.transpose(np.fliplr(x)),\n",
    "    lambda x: np.transpose(np.flipud(x)),\n",
    "    lambda x: np.transpose(np.fliplr(np.flipud(x))),\n",
    "]\n",
    "\n",
    "\n",
    "# transformations = [\n",
    "#     lambda x: x,                         # Identity\n",
    "#     lambda x: np.rot90(x, 1),            # Rotate 90°\n",
    "#     lambda x: np.rot90(x, 2),            # Rotate 180°\n",
    "#     lambda x: np.rot90(x, 3),            # Rotate 270°\n",
    "#     lambda x: np.fliplr(x),              # Horizontal reflection\n",
    "#     lambda x: np.flipud(x),              # Vertical reflection\n",
    "#     lambda x: np.transpose(x),           # Diagonal reflection (TL-BR)\n",
    "#     # lambda x: np.fliplr(np.transpose(x)) # Diagonal reflection (TR-BL)\n",
    "# ]\n",
    "\n",
    "# inverse_transformations = [\n",
    "#     lambda x: x,                         # Identity\n",
    "#     lambda x: np.rot90(x, 3),            # Rotate 90° inverse (rotate 270°)\n",
    "#     lambda x: np.rot90(x, 2),            # Rotate 180° inverse\n",
    "#     lambda x: np.rot90(x, 1),            # Rotate 270° inverse (rotate 90°)\n",
    "#     lambda x: np.fliplr(x),              # Horizontal reflection inverse\n",
    "#     lambda x: np.flipud(x),              # Vertical reflection inverse\n",
    "#     lambda x: np.transpose(x),           # Diagonal reflection (TL-BR) inverse\n",
    "#     # lambda x: np.transpose(np.fliplr(x)) # Diagonal reflection (TR-BL) inverse\n",
    "# ]\n",
    "\n",
    "original_actions = np.array(range(n * n)).reshape(n, n)\n",
    "for i, transform in enumerate(transformations):\n",
    "    assert (\n",
    "        inverse_transformations[i](transform(original_actions)).flatten().tolist()\n",
    "        == original_actions.flatten().tolist()\n",
    "    )\n",
    "\n",
    "transformed_actions = [transform(original_actions).flatten().tolist() for transform in transformations]\n",
    "for i in range(len(transformed_actions)):\n",
    "    for j in range(i + 1, len(transformed_actions)):\n",
    "        assert transformed_actions[i] != transformed_actions[j]\n",
    "\n",
    "\n",
    "def generate_win_conditions(width, height, win_length):\n",
    "    win_conditions = []\n",
    "\n",
    "    # Rows\n",
    "    for row in range(height):\n",
    "        for start_col in range(width - win_length + 1):  # Ensure win_length-length sequence fits\n",
    "            win_conditions.append([start_col + row * width + offset for offset in range(win_length)])\n",
    "\n",
    "    # Columns\n",
    "    for col in range(width):\n",
    "        for start_row in range(height - win_length + 1):  # Ensure win_length-length sequence fits\n",
    "            win_conditions.append([col + (start_row + offset) * width for offset in range(win_length)])\n",
    "\n",
    "    # Diagonals (top-left to bottom-right)\n",
    "    for row in range(height - win_length + 1):\n",
    "        for col in range(width - win_length + 1):  # Ensure win_length-length sequence fits\n",
    "            win_conditions.append([(col + offset) + (row + offset) * width for offset in range(win_length)])\n",
    "\n",
    "    # Diagonals (top-right to bottom-left)\n",
    "    for row in range(height - win_length + 1):\n",
    "        for col in range(win_length - 1, width):  # Ensure win_length-length sequence fits\n",
    "            win_conditions.append([(col - offset) + (row + offset) * width for offset in range(win_length)])\n",
    "\n",
    "    return win_conditions\n",
    "\n",
    "\n",
    "def is_won(board, player, win_conditions):\n",
    "    # Check if any win condition is satisfied\n",
    "    for condition in win_conditions:\n",
    "        if all(board[pos] == player for pos in condition):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "win_conditions = generate_win_conditions(n, n, 3)\n",
    "\n",
    "\n",
    "def generate_all_valid_boards():\n",
    "    symbols = [\" \", \"X\", \"O\"]\n",
    "    all_boards = list(product(symbols, repeat=n * n))  # Generate all 3^(n*n) combinations\n",
    "    assert (3 ** (n * n)) == len(all_boards)\n",
    "    all_valid_boards = []\n",
    "\n",
    "    for board in all_boards:\n",
    "        x_count = board.count(\"X\")\n",
    "        o_count = board.count(\"O\")\n",
    "\n",
    "        # Valid boards must satisfy these conditions:\n",
    "        if x_count == o_count or x_count == o_count + 1:\n",
    "            # if not is_won(board, 'X', win_conditions) and not is_won(board, 'O', win_conditions):\n",
    "            all_valid_boards.append(board)\n",
    "\n",
    "    return all_valid_boards\n",
    "\n",
    "\n",
    "def board_to_matrix(board):\n",
    "    return np.array(board).reshape(n, n)\n",
    "\n",
    "\n",
    "def matrix_to_board(matrix):\n",
    "    return matrix.flatten().tolist()\n",
    "\n",
    "\n",
    "def generate_symmetries(board):\n",
    "    matrix = board_to_matrix(board)\n",
    "    symmetries = [transform(matrix) for transform in transformations]\n",
    "    return [matrix_to_board(sym) for sym in symmetries]\n",
    "\n",
    "\n",
    "def get_canonical_representation(board):\n",
    "    symmetries = generate_symmetries(board)\n",
    "    min_symmetry = min(symmetries)\n",
    "    return tuple(min_symmetry), symmetries.index(min_symmetry)\n",
    "\n",
    "\n",
    "# Generate all empty positions on the board\n",
    "def get_empty_positions(board):\n",
    "    return [i for i, cell in enumerate(board) if cell == \" \"]\n",
    "\n",
    "\n",
    "def display_board(board):\n",
    "    print(f\" {board[0]} | {board[1]} | {board[2]} \")\n",
    "    print(\"---+---+---\")\n",
    "    print(f\" {board[3]} | {board[4]} | {board[5]} \")\n",
    "    print(\"---+---+---\")\n",
    "    print(f\" {board[6]} | {board[7]} | {board[8]} \")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def get_next_player(board):\n",
    "    x_count = board.count(\"X\")\n",
    "    o_count = board.count(\"O\")\n",
    "    return \"X\" if x_count == o_count else \"O\"\n",
    "\n",
    "\n",
    "def get_next_board(board, action):\n",
    "    new_board = list(board)\n",
    "    next_player = get_next_player(board)\n",
    "    if next_player == \"X\":\n",
    "        new_board[action] = \"X\"\n",
    "    else:\n",
    "        new_board[action] = \"O\"\n",
    "\n",
    "    return tuple(new_board)\n",
    "\n",
    "\n",
    "# Generate all valid Tic-Tac-Toe boards\n",
    "all_valid_boards = generate_all_valid_boards()\n",
    "state_action_pairs = 0\n",
    "for valid_board in all_valid_boards:\n",
    "    empty_positions = get_empty_positions(valid_board)\n",
    "    state_action_pairs += len(empty_positions)\n",
    "\n",
    "# Generate all canonical Tic-Tac-Toe boards\n",
    "all_canonical_boards = set()\n",
    "get_canonical_boards = {}\n",
    "get_transform = {}\n",
    "get_inverse_transform = {}\n",
    "get_canonical_actions = {}\n",
    "get_inverse_canonical_actions = {}\n",
    "for valid_board in all_valid_boards:\n",
    "    canonical_board, transform_idx = get_canonical_representation(valid_board)\n",
    "    all_canonical_boards.add(canonical_board)\n",
    "    get_canonical_boards[valid_board] = canonical_board\n",
    "    get_transform[valid_board] = transformations[transform_idx]\n",
    "    get_inverse_transform[valid_board] = inverse_transformations[transform_idx]\n",
    "    get_inverse_canonical_actions[valid_board] = get_transform[valid_board](original_actions).flatten().tolist()\n",
    "    get_canonical_actions[valid_board] = get_inverse_transform[valid_board](original_actions).flatten().tolist()\n",
    "\n",
    "all_canonical_boards = sorted(list(all_canonical_boards))\n",
    "all_canonical_actions = {}\n",
    "canonical_state_action_pairs = 0\n",
    "for canonical_board in all_canonical_boards:\n",
    "    empty_positions = get_empty_positions(canonical_board)\n",
    "    all_canonical_actions[canonical_board] = empty_positions\n",
    "    canonical_state_action_pairs += len(empty_positions)\n",
    "\n",
    "\n",
    "def get_canonical_board(board):\n",
    "    return get_canonical_boards[tuple(board)]\n",
    "\n",
    "\n",
    "def get_canonical_action(board, action):\n",
    "    return get_canonical_actions[board][action]\n",
    "\n",
    "\n",
    "def get_inverse_canonical_action(board, canonical_action):\n",
    "    return get_inverse_canonical_actions[board][canonical_action]\n",
    "\n",
    "\n",
    "def canonicalize(board, action):\n",
    "    canonical_board = get_canonical_board(board)\n",
    "    canonical_action = get_canonical_action(board, action)\n",
    "    return canonical_board, canonical_action\n",
    "\n",
    "\n",
    "canonical_board_to_next_canonical_board = {}\n",
    "all_next_canonical_boards = set()\n",
    "for canonical_board in all_canonical_boards:\n",
    "    canonical_actions_to_next_canonical_board = {}\n",
    "    for canonical_action in all_canonical_actions[canonical_board]:\n",
    "        next_board = get_next_board(canonical_board, canonical_action)\n",
    "        # if not is_won(next_board, 'X', win_conditions) and not is_won(next_board, 'O', win_conditions):\n",
    "        next_canonical_board = get_canonical_board(next_board)\n",
    "        all_next_canonical_boards.add(next_canonical_board)\n",
    "        canonical_actions_to_next_canonical_board[canonical_action] = next_canonical_board\n",
    "\n",
    "    canonical_board_to_next_canonical_board[canonical_board] = canonical_actions_to_next_canonical_board\n",
    "\n",
    "qMatrix = defaultdict(lambda: -1)\n",
    "for i, next_canonical_board in enumerate(all_next_canonical_boards):\n",
    "    qMatrix[next_canonical_board] = i\n",
    "\n",
    "\n",
    "def get(board=None, action=None):\n",
    "    if board is None and action is None:\n",
    "        return qMatrix\n",
    "    if action is None and board is not None:\n",
    "        actions = get_empty_positions(board)\n",
    "        canonical_actions = [get_canonical_action(board, action) for action in actions]\n",
    "        canonical_board = get_canonical_board(board)\n",
    "        return [\n",
    "            qMatrix[canonical_board_to_next_canonical_board[canonical_board][canonical_action]]\n",
    "            for canonical_action in canonical_actions\n",
    "        ]\n",
    "    if action is not None and board is not None:\n",
    "        return qMatrix[\n",
    "            canonical_board_to_next_canonical_board[get_canonical_board(board)][get_canonical_action(board, action)]\n",
    "        ]\n",
    "\n",
    "\n",
    "def Qset(board, action, value):\n",
    "    qMatrix[\n",
    "        canonical_board_to_next_canonical_board[get_canonical_board(board)][get_canonical_action(board, action)]\n",
    "    ] = value\n",
    "\n",
    "\n",
    "def displayQ(valid_board):\n",
    "    valid_actions = get_empty_positions(valid_board)\n",
    "    canonical_board = get_canonical_board(valid_board)\n",
    "    Qvalid_board = list(valid_board)\n",
    "    for valid_action in valid_actions:\n",
    "        Qvalid_board[valid_action] = qMatrix[\n",
    "            canonical_board_to_next_canonical_board[canonical_board][get_canonical_action(valid_board, valid_action)]\n",
    "        ]\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(np.array(Qvalid_board).reshape(n, n))\n",
    "\n",
    "\n",
    "print(f\"Number of boards:                               {(3**(n*n))}\")\n",
    "print(f\"Number of state-action pairs:                   {(3**(n*n))*(n*n)}\")\n",
    "print(f\"Number of valid boards:                         {len(all_valid_boards)}\")\n",
    "print(f\"Number of valid state-action pairs:             {state_action_pairs}\")\n",
    "print(f\"Number of canonical boards:                     {len(all_canonical_boards)}\")\n",
    "print(f\"Number of canonical state-action pairs:         {canonical_state_action_pairs}\")\n",
    "print(f\"Number of next canonical boards:                {len(all_next_canonical_boards)}\")\n",
    "print(f\"Number of reduced canonical state-action pairs: {len(all_next_canonical_boards)}\")\n",
    "\n",
    "board1 = (\"X\", \" \", \" \", \" \", \"O\", \" \", \" \", \" \", \" \")\n",
    "board2 = (\" \", \" \", \" \", \" \", \"O\", \"X\", \" \", \" \", \" \")\n",
    "displayQ(board1)\n",
    "displayQ(board2)\n",
    "assert get(board1, 5) == get(board2, 0)\n",
    "print(f\"{get(board1, 5)} == {get(board2, 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of boards:                               19683\n",
    "Number of state-action pairs:                   177147\n",
    "Number of valid boards:                         6046\n",
    "Number of valid state-action pairs:             19107\n",
    "Number of canonical boards:                     1520\n",
    "Number of canonical state-action pairs:         4808\n",
    "Number of next canonical boards:                1073\n",
    "Number of reduced canonical state-action pairs: 1073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def permutation_matrix(permutation):\n",
    "    n = len(permutation)\n",
    "    return np.eye(n, dtype=int)[permutation]\n",
    "\n",
    "\n",
    "def is_group(matrix_set):\n",
    "    identity = np.eye(matrix_set[0].shape[0])  # Identity matrix of appropriate size\n",
    "\n",
    "    # 1. Check Closure\n",
    "    for A in matrix_set:\n",
    "        for B in matrix_set:\n",
    "            if not any(np.allclose(A @ B, C) for C in matrix_set):\n",
    "                return False, \"Closure failed\"\n",
    "\n",
    "    # 2. Associativity (already guaranteed for matrices)\n",
    "\n",
    "    # 3. Check Identity\n",
    "    if not any(np.allclose(identity, A) for A in matrix_set):\n",
    "        return False, \"Identity missing\"\n",
    "\n",
    "    # 4. Check Inverses\n",
    "    for A in matrix_set:\n",
    "        try:\n",
    "            A_inv = np.linalg.inv(A)\n",
    "        except np.linalg.LinAlgError:  # Matrix is not invertible\n",
    "            return False, f\"Matrix {A} has no inverse\"\n",
    "        if not any(np.allclose(A_inv, B) for B in matrix_set):\n",
    "            return False, f\"Inverse of {A} is not in the set\"\n",
    "\n",
    "    return True, \"The set forms a group\"\n",
    "\n",
    "\n",
    "def construct_group(matrices):\n",
    "    group = set(tuple(mat.flatten()) for mat in matrices)  # Use set for uniqueness\n",
    "\n",
    "    # Identity matrix of appropriate size\n",
    "    size = matrices[0].shape[0]\n",
    "    identity = np.eye(size)\n",
    "    group.add(tuple(identity.flatten()))\n",
    "\n",
    "    # Add inverses and closure under multiplication\n",
    "    added = True\n",
    "    while added:\n",
    "        added = False\n",
    "        current_group = list(group)\n",
    "\n",
    "        # Closure: Multiply all pairs\n",
    "        for mat1 in current_group:\n",
    "            for mat2 in current_group:\n",
    "                product = np.dot(np.array(mat1).reshape(size, size), np.array(mat2).reshape(size, size))\n",
    "                if tuple(product.flatten()) not in group:\n",
    "                    group.add(tuple(product.flatten()))\n",
    "                    added = True\n",
    "\n",
    "        # Add inverses\n",
    "        for mat in current_group:\n",
    "            mat_np = np.array(mat).reshape(size, size)\n",
    "            try:\n",
    "                inverse = np.linalg.inv(mat_np)\n",
    "            except np.linalg.LinAlgError:\n",
    "                continue  # Skip non-invertible matrices\n",
    "            if tuple(inverse.flatten()) not in group:\n",
    "                group.add(tuple(inverse.flatten()))\n",
    "                added = True\n",
    "\n",
    "    # Convert back to numpy array format\n",
    "    group = [np.array(g).reshape(size, size) for g in group]\n",
    "    return group\n",
    "\n",
    "\n",
    "def rank_factorization(A, r):\n",
    "    \"\"\"\n",
    "    Perform a rank-r factorization of matrix A using SVD.\n",
    "\n",
    "    Parameters:\n",
    "        A (numpy.ndarray): The input matrix (m x n).\n",
    "        r (int): Desired rank for the factorization.\n",
    "\n",
    "    Returns:\n",
    "        U (numpy.ndarray): Matrix of dimensions (m x r).\n",
    "        V (numpy.ndarray): Matrix of dimensions (r x n).\n",
    "    \"\"\"\n",
    "    # Perform SVD\n",
    "    U, S, VT = np.linalg.svd(A, full_matrices=False)\n",
    "\n",
    "    # Truncate to rank r\n",
    "    U_r = U[:, :r]\n",
    "    S_r = np.diag(S[:r])  # Convert top r singular values to a diagonal matrix\n",
    "    VT_r = VT[:r, :]\n",
    "\n",
    "    # Construct the factorization\n",
    "    U_factor = U_r @ S_r  # m x r matrix\n",
    "    V_factor = VT_r  # r x n matrix\n",
    "\n",
    "    return U_factor, V_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformationsud = [\n",
    "    lambda x: x,  # Identity\n",
    "    lambda x: np.flipud(x),  # Horizontal reflection\n",
    "]\n",
    "\n",
    "transformationslr = [\n",
    "    lambda x: x,  # Identity\n",
    "    lambda x: np.fliplr(x),  # Horizontal reflection\n",
    "]\n",
    "\n",
    "transformationsrot = [\n",
    "    lambda x: x,  # Identity\n",
    "    lambda x: np.rot90(x, 1),  # Rotate 90°\n",
    "    lambda x: np.rot90(x, 2),  # Rotate 180°\n",
    "    lambda x: np.rot90(x, 3),  # Rotate 270°\n",
    "]\n",
    "\n",
    "transformationslrud = [\n",
    "    lambda x: x,  # Identity\n",
    "    lambda x: np.fliplr(x),  # Horizontal reflection\n",
    "    lambda x: np.flipud(x),  # Vertical reflection\n",
    "    lambda x: np.flipud(np.fliplr(x)),  # Vertical reflection\n",
    "]\n",
    "\n",
    "transformations = [\n",
    "    lambda x: x,  # Identity\n",
    "    lambda x: np.fliplr(x),  # Horizontal reflection\n",
    "    lambda x: np.flipud(x),  # Vertical reflection\n",
    "    lambda x: np.flipud(np.fliplr(x)),  # Vertical reflection\n",
    "    lambda x: np.transpose(x),  # Diagonal reflection (TL-BR)\n",
    "    lambda x: np.fliplr(np.transpose(x)),  # Horizontal reflection\n",
    "    lambda x: np.flipud(np.transpose(x)),  # Vertical reflection\n",
    "    lambda x: np.flipud(np.fliplr(np.transpose(x))),  # Vertical reflection\n",
    "]\n",
    "\n",
    "N = 3\n",
    "indices = np.array(list(range(N * N))).reshape(N, N)\n",
    "permutations = [transform(indices).flatten().tolist() for transform in transformations]\n",
    "Ps = np.array([permutation_matrix(permutation) for permutation in permutations])\n",
    "\n",
    "result, message = is_group(Ps)\n",
    "print(message)\n",
    "\n",
    "group = construct_group(Ps)\n",
    "print(len(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP = np.sum(group, axis=0)\n",
    "print(PP)\n",
    "print(np.linalg.matrix_rank(PP))\n",
    "\n",
    "U, V = rank_factorization(PP, np.linalg.matrix_rank(PP))\n",
    "threshold = 10e-10\n",
    "V[np.abs(V) < threshold] = 0\n",
    "U[np.abs(U) < threshold] = 0\n",
    "U = U\n",
    "V = V\n",
    "print(U)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols, Matrix\n",
    "\n",
    "num_symbols = N**2  # Number of symbols you want to create\n",
    "matrix_names = [f\"w{i}{j}\" for i in range(1, num_symbols + 1) for j in range(1, num_symbols + 1)]\n",
    "matrix_symbols = symbols(matrix_names)\n",
    "cell_names = [f\"s{i}\" for i in range(1, num_symbols + 1)]\n",
    "cell_symbols = symbols(cell_names)\n",
    "cell_vector = Matrix(cell_symbols)\n",
    "W = Matrix([[matrix_symbols[j + (num_symbols) * i] for i in range(num_symbols)] for j in range(num_symbols)]).T\n",
    "PP0 = Matrix(PP)\n",
    "VV = Matrix(V)\n",
    "display(PP0 * cell_vector)\n",
    "display(VV * cell_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_cell_vector = PP0 * cell_vector\n",
    "np.array(transformed_cell_vector).reshape(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((PP // 2) @ [1, 0, 0, 0, 1, 0, 0, -1, -1]).reshape(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_symbols = symbols([\"a_+\", \"a_0\", \"a_-\"])\n",
    "all_states = list(product(state_symbols, repeat=N * N))\n",
    "s0 = Matrix(all_states[1000])\n",
    "V_int = (2 * V).astype(int)\n",
    "VV = Matrix(V_int)\n",
    "display(VV * s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_valid_states = []\n",
    "for state in all_states:\n",
    "    x_count = state.count(state_symbols[0])\n",
    "    o_count = state.count(state_symbols[-1])\n",
    "    if x_count == o_count or x_count == o_count + 1:\n",
    "        all_valid_states.append(state)\n",
    "\n",
    "all_transformed_states = []\n",
    "for state in all_states:\n",
    "    all_transformed_states.append(tuple(VV @ Matrix(state)))\n",
    "\n",
    "print(len(set(all_transformed_states)))\n",
    "\n",
    "set(all_transformed_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = [1, 2, 3]\n",
    "all_states = np.array(list(product(symbols, repeat=N * N)))\n",
    "print(all_states.shape)\n",
    "all_valid_states = []\n",
    "for state in all_states:\n",
    "    x_count = list(state).count(2)\n",
    "    o_count = list(state).count(3)\n",
    "\n",
    "    # Valid boards must satisfy these conditions:\n",
    "    if x_count == o_count or x_count == o_count + 1:\n",
    "        # if not is_won(board, 'X', win_conditions) and not is_won(board, 'O', win_conditions):\n",
    "        all_valid_states.append(state)\n",
    "\n",
    "    # if sum(state) == 0 or sum(state) == 1:\n",
    "    #     all_valid_states.append(state)\n",
    "\n",
    "all_valid_states = np.array(all_valid_states)\n",
    "print(all_valid_states.shape)\n",
    "all_transformed_states = set()\n",
    "for state in all_valid_states:\n",
    "    all_transformed_states.add(tuple(V @ state))\n",
    "\n",
    "all_transformed_states = np.array(list(all_transformed_states))\n",
    "print(all_transformed_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qMatrix = defaultdict(lambda: -1)\n",
    "board = (\" \", \" \", \" \", \" \", \" \", \" \", \" \", \" \", \" \")\n",
    "Qset(board, 0, 0.2)\n",
    "displayQ(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_board = all_valid_boards[5]\n",
    "actions = get_empty_positions(valid_board)\n",
    "canonical_actions = [get_canonical_action(valid_board, action) for action in actions]\n",
    "print(f\"Board:             {valid_board}\")\n",
    "print(f\"Canonical board:   {get_canonical_board(valid_board)}\")\n",
    "print(f\"Actions:           {actions}\")\n",
    "print(f\"Canonical actions: {sorted(canonical_actions)}\")\n",
    "print(f\"Canonical actions: {sorted(all_canonical_actions[get_canonical_board(valid_board)])}\")\n",
    "\n",
    "tot = 0\n",
    "for i, valid_board in enumerate(all_valid_boards):\n",
    "    actions = get_empty_positions(valid_board)\n",
    "    canonical_board = get_canonical_board(valid_board)\n",
    "    canonical_actions1 = sorted(all_canonical_actions[canonical_board])\n",
    "    canonical_actions2 = sorted([get_canonical_action(valid_board, action) for action in actions])\n",
    "    if not canonical_actions2 == canonical_actions1:\n",
    "        tot += 1\n",
    "\n",
    "print(f\"Number of wrong canonical actions:      {tot}/{len(all_valid_boards)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    if i == 10 - 1:\n",
    "        print(f\"final i: {i}\")\n",
    "    else:\n",
    "        print(f\"{i}, {i + 1}\")\n",
    "\n",
    "for i in reversed(range(10)):\n",
    "    if i == 10 - 1:\n",
    "        print(f\"final i: {i}\")\n",
    "    else:\n",
    "        print(f\"{i}, {i + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# initializing deque\n",
    "de = collections.deque([1, 2, 3], maxlen=3)\n",
    "print(\"deque: \", de)\n",
    "\n",
    "# using append() to insert element at right end\n",
    "# inserts 4 at the end of deque\n",
    "de.append(4)\n",
    "\n",
    "# printing modified deque\n",
    "print(\"\\nThe deque after appending at right is : \")\n",
    "print(de)\n",
    "\n",
    "# using appendleft() to insert element at left end\n",
    "# inserts 6 at the beginning of deque\n",
    "de.appendleft(6)\n",
    "\n",
    "# printing modified deque\n",
    "print(\"\\nThe deque after appending at left is : \")\n",
    "print(de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python3 program to demonstrate\n",
    "# the use of sample() function .\n",
    "\n",
    "# import random\n",
    "import random\n",
    "\n",
    "\n",
    "# Prints list of random items of\n",
    "# length 3 from the given list.\n",
    "list1 = [1, 2, 3, 4, 5, 6]\n",
    "print(\"With list:\", random.sample(list1, 3))\n",
    "print(\"With list:\", random.sample(list1, 2))\n",
    "\n",
    "# Prints list of random items of\n",
    "# length 4 from the given string.\n",
    "string = \"GeeksforGeeks\"\n",
    "print(\"With string:\", random.sample(string, 4))\n",
    "\n",
    "# Prints list of random items of\n",
    "# length 4 from the given tuple.\n",
    "tuple1 = (\"ankit\", \"geeks\", \"computer\", \"science\", \"portal\", \"scientist\", \"btech\")\n",
    "print(\"With tuple:\", random.sample(tuple1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyComputeDict(dict):\n",
    "    def __init__(self, compute_func, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.compute_func = compute_func\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key not in self:\n",
    "            # Compute and store the value if it doesn't exist\n",
    "            self[key] = self.compute_func(key)\n",
    "        return super().__getitem__(key)\n",
    "\n",
    "\n",
    "def compute_value(key):\n",
    "    # Replace this with the actual computation logic\n",
    "    return key**2\n",
    "\n",
    "\n",
    "# Usage\n",
    "my_dict = LazyComputeDict(lambda key: key**2)\n",
    "\n",
    "# Accessing a key\n",
    "key = 50\n",
    "value = my_dict[key]  # Computes and stores the value on the fly\n",
    "print(value)\n",
    "\n",
    "\n",
    "def create_level2_lazy_dict(compute_func):\n",
    "    def level1_compute(outer_key):\n",
    "        # Create another LazyComputeDict for the second level\n",
    "        return LazyComputeDict(lambda inner_key: compute_func(outer_key, inner_key))\n",
    "\n",
    "    # Return the top-level LazyComputeDict\n",
    "    return LazyComputeDict(level1_compute)\n",
    "\n",
    "\n",
    "# Create the level-2 LazyComputeDict\n",
    "nested_dict = create_level2_lazy_dict(compute_value)\n",
    "\n",
    "# Accessing values dynamically\n",
    "print(nested_dict[\"group1\"][\"item1\"])  # Triggers computation for ('group1', 'item1')\n",
    "print(nested_dict[\"group2\"][\"item2\"])  # Triggers computation for ('group2', 'item2')\n",
    "\n",
    "# Accessing the entire structure\n",
    "print(nested_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_to_board_translation = {\"X\": 1, \"O\": -1, \" \": 0}\n",
    "board_to_state_translation = {}\n",
    "for key, value in state_to_board_translation.items():\n",
    "    print(f\"{key} -> {value}\")\n",
    "    board_to_state_translation[value] = key\n",
    "\n",
    "board_to_state_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "\n",
    "replay_buffer = deque(maxlen=100)\n",
    "batch_size = 16\n",
    "for i in range(100):\n",
    "    replay_buffer.append(i)\n",
    "\n",
    "print(replay_buffer)\n",
    "print(random.sample(replay_buffer, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data for demonstration (Replace these with actual `meanlossX` and `meanavg_action_valueX` values)\n",
    "import numpy as np\n",
    "\n",
    "meanlossX = np.random.rand(100)  # Replace with actual data\n",
    "meanavg_action_valueX = np.random.rand(100)  # Replace with actual data\n",
    "\n",
    "# Create a figure with two subplots next to each other\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))  # 1 row, 2 columns\n",
    "\n",
    "# Plot the first graph: Mean Loss\n",
    "axs[0].plot(meanlossX, label=\"Mean Loss\")\n",
    "axs[0].set_title(\"Mean Loss Over Time\")\n",
    "axs[0].set_xlabel(\"Time\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].grid(True)\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot the second graph: Mean Average Action Value\n",
    "axs[1].plot(meanavg_action_valueX, label=\"Mean Avg Action Value\", color=\"orange\")\n",
    "axs[1].set_title(\"Mean Avg Action Value Over Time\")\n",
    "axs[1].set_xlabel(\"Time\")\n",
    "axs[1].set_ylabel(\"Action Value\")\n",
    "axs[1].grid(True)\n",
    "axs[1].legend()\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_nested(d):\n",
    "    \"\"\"Check if a dictionary is nested.\"\"\"\n",
    "    return any(isinstance(value, dict) for value in d.values())\n",
    "\n",
    "\n",
    "def extract_values(d):\n",
    "    \"\"\"Extract all values from a potentially nested dictionary.\"\"\"\n",
    "    values = []\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, dict):  # If the value is a dictionary, recurse\n",
    "            values.extend(extract_values(value))\n",
    "        else:\n",
    "            values.append(value)\n",
    "    return values\n",
    "\n",
    "\n",
    "# Example usage\n",
    "data = {\"a\": 1, \"b\": {\"c\": 2, \"d\": {\"e\": 3, \"f\": 4}}, \"g\": 5}\n",
    "\n",
    "# Check if the dictionary is nested\n",
    "print(\"Is nested:\", is_nested(data))\n",
    "\n",
    "# Extract all values\n",
    "all_values = extract_values(data)\n",
    "print(\"All values:\", all_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "cell_vector = torch.tensor([[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0]])\n",
    "action = torch.tensor([8])\n",
    "cell_vector.gather(1, action.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "states = (np.array([[0, 0, 0, 0, -1, 1, -1, 1, 0]]), np.array([[0, 0, 0, 0, -1, 1, 0, 0, 0]]))\n",
    "actions = (5, 5)\n",
    "states = torch.FloatTensor(states)\n",
    "actions = torch.LongTensor(actions).unsqueeze(1)\n",
    "print(states)\n",
    "print(actions)\n",
    "states.gather(2, actions.unsqueeze(2)).squeeze(2)\n",
    "next_q_values = states.max(2, keepdim=True)[0].squeeze(2)\n",
    "print(next_q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = (np.array([[0, 0, 0, 0, -1, 1, -1, 1, 0]]), np.array([[0, 0, 0, 0, -1, 1, 0, 0, 0]]))\n",
    "print(states)\n",
    "states = np.array((np.array([[0, 0, 0, 0, -1, 1, -1, 1, 0]]), np.array([[0, 0, 0, 0, -1, 1, 0, 0, 0]])))\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"X\"] * 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dill\n",
    "\n",
    "# with open('SymmetricQ_optimalX.pkl', 'wb') as f:\n",
    "#     dill.dump(Q1.get(), f)\n",
    "\n",
    "# with open('SymmetricQ_optimalO.pkl', 'wb') as f:\n",
    "#     dill.dump(Q2.get(), f)\n",
    "\n",
    "# with open('TotallySymmetricQ_optimalX.pkl', 'wb') as f:\n",
    "#     dill.dump(Q1.get(), f)\n",
    "\n",
    "# with open('TotallySymmetricQ_optimalO.pkl', 'wb') as f:\n",
    "#     dill.dump(Q2.get(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3])  # Shape: (3,)\n",
    "unsqueezed_tensor = tensor.unsqueeze(0)  # Adds a new dimension at index 0\n",
    "print(unsqueezed_tensor)  # Shape: (1, 3)\n",
    "\n",
    "unsqueezed_tensor = tensor.unsqueeze(1)  # Adds a new dimension at index 1\n",
    "print(unsqueezed_tensor)  # Shape: (3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.tensor([[[1], [2], [3]]])  # Shape: (1, 3, 1)\n",
    "squeezed_tensor = tensor.squeeze()  # Removes all size-1 dimensions\n",
    "print(squeezed_tensor)  # Shape: (3,)\n",
    "\n",
    "# Squeezing a specific dimension\n",
    "squeezed_tensor = tensor.squeeze(0)  # Removes the size-1 dimension at index 0\n",
    "print(squeezed_tensor)  # Shape: (3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.mps.is_built()\n",
    "device = torch.device(\"mps\")\n",
    "tensor = torch.ones((3, 3), device=device)\n",
    "print(\"Tensor on MPS device:\", tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
