{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcomes:\n",
      "X wins: 0.676696, O wins: 0.18572133333333332, draws: 0.13758266666666666\n"
     ]
    }
   ],
   "source": [
    "# Let the games begin\n",
    "\n",
    "from Matrix import Matrix, QMatrix\n",
    "from SymmetricMatrix import SymmetricMatrix, QSymmetricMatrix\n",
    "from SymmetricMatrix import TotallySymmetricMatrix, QTotallySymmetricMatrix\n",
    "from playGame import play_game, initialize_board, get_empty_positions\n",
    "\n",
    "\n",
    "# Parameters\n",
    "params = {\n",
    "    'Q_initial_value' : 0.0, # initial Q value\n",
    "    'alpha_start' : 0.1,  # initial learning rate\n",
    "    'alpha_min' : 0.1, # minimum learning rate\n",
    "    'gamma' : 0.99,  # discount factor\n",
    "    'epsilon_start' : 0.5,  # initial exploration rate\n",
    "    'epsilon_min' : 0.25, # minimum exploration rate\n",
    "    'waiting_time' : 1.0, # waiting in seconds for display\n",
    "    'episode' : 0, # number of episodes played during training\n",
    "    'outcomes' : {'X' : 0, 'O' : 0, 'D' : 0}, # dictionary to save the outcomes for games ('X' = X wins, 'O' = O wins, 'D' = draws) \n",
    "    'nr_of_episodes' : 500000, # number of episodes for training\n",
    "    'eps' : {'X' : -1.0, 'O' : -1.0}, # epsilon values for non-training determine how randomized the computer plays\n",
    "    'rewards' : {'X' : 1.0, 'O' : -1.0, 'D' : 0.0}, # dictionary for rewards\n",
    "}\n",
    "\n",
    "# Initialize matrices\n",
    "\n",
    "# Q = QMatrix(file='Q.pkl')\n",
    "# Q = QMatrix(default_value=params['Q_initial_value'])\n",
    "# Visits = Matrix(default_value=0)\n",
    "# Rewards = Matrix(default_value=0)\n",
    "\n",
    "# # Q = QSymmetricMatrix(file='SymmetricQ.pkl')\n",
    "# Q = QSymmetricMatrix(default_value=params['Q_initial_value'])\n",
    "# Visits = SymmetricMatrix(default_value=0)\n",
    "# Rewards = SymmetricMatrix(default_value=0.0)\n",
    "\n",
    "# Q = QTotallySymmetricMatrix(file='TotallySymmetricQ.pkl')\n",
    "Q = QTotallySymmetricMatrix(default_value=params['Q_initial_value'])\n",
    "Visits = TotallySymmetricMatrix(default_value=0)\n",
    "Rewards = TotallySymmetricMatrix(default_value=0.0)\n",
    "\n",
    "matrices = (Q, Visits, Rewards)\n",
    "\n",
    "nr_of_episodes = 1500000\n",
    "params['nr_of_episodes'] = nr_of_episodes\n",
    "params['episode'] = 0\n",
    "\n",
    "flags = {\n",
    "    'training': True,\n",
    "    'display': False,\n",
    "    'interactive': False\n",
    "}\n",
    "for _ in range(nr_of_episodes):\n",
    "    play_game(matrices, params, flags=flags)\n",
    "    params['episode'] += 1\n",
    "\n",
    "print(\"Outcomes:\")\n",
    "print(f\"X wins: {params['outcomes']['X']/nr_of_episodes}, O wins: {params['outcomes']['O']/nr_of_episodes}, draws: {params['outcomes']['D']/nr_of_episodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcomes with players choosing actions based on Q-values:\n",
      "X wins: 0.0, O wins: 0.0, draws: 1.0\n"
     ]
    }
   ],
   "source": [
    "nr_of_episodes = 5000\n",
    "params['nr_of_episodes'] = nr_of_episodes\n",
    "params['eps'] = {'X' : -1.0, 'O' : -1.0}\n",
    "params['outcomes'] = {'X' : 0, 'O' : 0, 'D' : 0}\n",
    "flags = {\n",
    "    'training': False,\n",
    "    'display': False,\n",
    "    'interactive': False\n",
    "}\n",
    "for _ in range(nr_of_episodes):\n",
    "    play_game(matrices, params, flags=flags)\n",
    "\n",
    "print(\"Outcomes with players choosing actions based on Q-values:\")\n",
    "print(f\"X wins: {params['outcomes']['X']/nr_of_episodes}, O wins: {params['outcomes']['O']/nr_of_episodes}, draws: {params['outcomes']['D']/nr_of_episodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dill\n",
    "\n",
    "# with open('SymmetricQ.pkl', 'wb') as f:\n",
    "#     dill.dump(Q.get(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = {\n",
    "    'training': False,\n",
    "    'display': True,\n",
    "    'interactive': False\n",
    "}\n",
    "# play_game(matrices, params, flags=flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = {\n",
    "    'training': False,\n",
    "    'display': True,\n",
    "    'interactive': True\n",
    "}\n",
    "# play_game(matrices, params, flags=flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q value for action 4 is 0.9557137055148663\n",
      "[['0.89094' '0.76624' '0.89094']\n",
      " ['0.76624' '0.95571' '0.76624']\n",
      " ['0.89094' '0.76624' '0.89094']]\n",
      "q value for action 8 is 0.9345649010819989\n",
      "[['0.93456' '0.96798' '0.93456']\n",
      " ['0.96798' 'X' '0.96798']\n",
      " ['0.93456' '0.96798' '0.93456']]\n",
      "q value for action 2 is 0.9534166592776611\n",
      "[['0.86742' '0.83043' '0.95342']\n",
      " ['0.83043' 'X' '0.93744']\n",
      " ['0.95342' '0.93744' 'O']]\n",
      "q value for action 7 is 0.8461417979412137\n",
      "[['0.98571' '0.99000' 'X']\n",
      " ['0.98809' 'X' '0.98978']\n",
      " ['0.84177' '0.84614' 'O']]\n",
      "q value for action 6 is 0.9999999999999994\n",
      "[['-0.95654' '-0.67337' 'X']\n",
      " ['-0.84545' 'X' '-0.62088']\n",
      " ['1.00000' 'O' 'O']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from playGame import get_empty_positions\n",
    "\n",
    "def displayQ(Q, board):\n",
    "    actions = get_empty_positions(board)\n",
    "    Qs = [f\"{Q.get(board, action):.5f}\" for action in actions]\n",
    "    Qboard = list(board)\n",
    "    for i, action in enumerate(actions):\n",
    "        Qboard[action] = Qs[i]\n",
    "\n",
    "    print(f\"{np.array(Qboard).reshape(3,3)}\")\n",
    "\n",
    "history = params['history']\n",
    "for i in range(len(history)):\n",
    "    board, action = history[i]\n",
    "    print(f\"q value for action {action} is {Q.get(board, action)}\")\n",
    "    displayQ(Q, board)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
