{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjakob_teraki\u001b[0m (\u001b[33mjakob_snn\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/jakob/TicTacToe/wandb/run-20241119_172343-d2kcorsq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jakob_snn/TicTacToe/runs/d2kcorsq' target=\"_blank\">sage-glade-7</a></strong> to <a href='https://wandb.ai/jakob_snn/TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jakob_snn/TicTacToe' target=\"_blank\">https://wandb.ai/jakob_snn/TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jakob_snn/TicTacToe/runs/d2kcorsq' target=\"_blank\">https://wandb.ai/jakob_snn/TicTacToe/runs/d2kcorsq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:d2kcorsq) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sage-glade-7</strong> at: <a href='https://wandb.ai/jakob_snn/TicTacToe/runs/d2kcorsq' target=\"_blank\">https://wandb.ai/jakob_snn/TicTacToe/runs/d2kcorsq</a><br/> View project at: <a href='https://wandb.ai/jakob_snn/TicTacToe' target=\"_blank\">https://wandb.ai/jakob_snn/TicTacToe</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241119_172343-d2kcorsq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:d2kcorsq). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/jakob/TicTacToe/wandb/run-20241119_172344-69faopzc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jakob_snn/TicTacToe/runs/69faopzc' target=\"_blank\">summer-yogurt-8</a></strong> to <a href='https://wandb.ai/jakob_snn/TicTacToe' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jakob_snn/TicTacToe' target=\"_blank\">https://wandb.ai/jakob_snn/TicTacToe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jakob_snn/TicTacToe/runs/69faopzc' target=\"_blank\">https://wandb.ai/jakob_snn/TicTacToe/runs/69faopzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let the games begin\n",
    "\n",
    "import copy\n",
    "import wandb\n",
    "\n",
    "from TicTacToe import TicTacToe\n",
    "from Agent import RandomAgent, HumanAgent\n",
    "from DeepQAgent import DeepQLearningAgent, DeepQPlayingAgent\n",
    "\n",
    "params = {\n",
    "    'nr_of_episodes' : 500000, # number of episodes for training\n",
    "    'rows' : 3, # rows of the board, rows = cols\n",
    "\n",
    "    'epsilon_start' : 0.15,  # initial exploration rate\n",
    "    'epsilon_min' : 0.005, # minimum exploration rate\n",
    "    'learning_rate': 0.0001, # learning rate\n",
    "    'gamma' : 0.95,  # discount factor\n",
    "\n",
    "    'switching' : True, # switch between X and O\n",
    "    'debug' : False, # print debug messages\n",
    "\n",
    "    # Parameters for DeepQAgent\n",
    "    'batch_size' : 16, # batch size for deep learning\n",
    "    'target_update_frequency' : 20, # target network update frequency\n",
    "    'evaluation' : True, # save data for evaluation\n",
    "    'double_q_learning' : False, # flag to switch on double Q-learnning\n",
    "    'device' : 'cpu', # device to use, 'cpu' or 'mps' or 'cuda' \n",
    "    'replay_buffer_length' : 10000, # replay buffer length\n",
    "    }\n",
    "\n",
    "rows = 4\n",
    "win_length = 4\n",
    "nr_of_episodes = 250000\n",
    "params['nr_of_episodes'] = nr_of_episodes\n",
    "params['rows'] = rows\n",
    "\n",
    "paramsX = copy.deepcopy(params)\n",
    "paramsO = copy.deepcopy(params)\n",
    "paramsX['player'] = 'X'\n",
    "paramsO['player'] = 'O'\n",
    "\n",
    "outcomes = {'X' : 0, 'O' : 0, 'D' : 0}\n",
    "\n",
    "learning_agent1 = DeepQLearningAgent(paramsX)\n",
    "learning_agent2 = DeepQLearningAgent(paramsO)\n",
    "# random_agent2 = RandomAgent(player='O', switching=False)\n",
    "\n",
    "# game = TicTacToe(learning_agent1, random_agent2, display=None, rows=rows, cols=rows, win_length=win_length)\n",
    "game = TicTacToe(learning_agent1, learning_agent2, display=None, rows=rows, cols=rows, win_length=win_length)\n",
    "\n",
    "for episode in range(nr_of_episodes):\n",
    "    outcome = game.play()\n",
    "    outcomes[outcome] += 1\n",
    "\n",
    "print(\"Outcomes during learning:\")\n",
    "print(f\"X wins: {outcomes['X']/nr_of_episodes}, O wins: {outcomes['O']/nr_of_episodes}, draws: {outcomes['D']/nr_of_episodes}\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_network1 = learning_agent1.q_network\n",
    "playing_agent1 = DeepQPlayingAgent(q_network1, player='X', switching=False)\n",
    "random_agent2 = RandomAgent(player='O', switching=False)\n",
    "\n",
    "game = TicTacToe(playing_agent1, random_agent2, display=None, rows=rows, cols=rows, win_length=win_length)\n",
    "nr_of_episodes = 1000\n",
    "outcomes = {'X' : 0, 'O' : 0, 'D' : 0}\n",
    "for episode in range(nr_of_episodes):\n",
    "    outcome = game.play()\n",
    "    outcomes[outcome] += 1\n",
    "\n",
    "print(\"Outcomes during playing:\")\n",
    "print(f\"X wins: {outcomes['X']/nr_of_episodes}, O wins: {outcomes['O']/nr_of_episodes}, draws: {outcomes['D']/nr_of_episodes}\")\n",
    "\n",
    "q_network2 = learning_agent2.q_network\n",
    "playing_agent2 = DeepQPlayingAgent(q_network2, player='O', switching=False)\n",
    "random_agent1 = RandomAgent(player='X', switching=False)\n",
    "\n",
    "game = TicTacToe(random_agent1, playing_agent2, display=None, rows=rows, cols=rows, win_length=win_length)\n",
    "nr_of_episodes = 1000\n",
    "outcomes = {'X' : 0, 'O' : 0, 'D' : 0}\n",
    "for episode in range(nr_of_episodes):\n",
    "    outcome = game.play()\n",
    "    outcomes[outcome] += 1\n",
    "\n",
    "print(\"Outcomes during playing:\")\n",
    "print(f\"X wins: {outcomes['X']/nr_of_episodes}, O wins: {outcomes['O']/nr_of_episodes}, draws: {outcomes['D']/nr_of_episodes}\")\n",
    "\n",
    "game = TicTacToe(playing_agent1, playing_agent2, display=None, rows=rows, cols=rows, win_length=win_length)\n",
    "nr_of_episodes = 1000\n",
    "outcomes = {'X' : 0, 'O' : 0, 'D' : 0}\n",
    "for episode in range(nr_of_episodes):\n",
    "    outcome = game.play()\n",
    "    outcomes[outcome] += 1\n",
    "\n",
    "print(\"Outcomes during playing:\")\n",
    "print(f\"X wins: {outcomes['X']/nr_of_episodes}, O wins: {outcomes['O']/nr_of_episodes}, draws: {outcomes['D']/nr_of_episodes}\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# torch.save(q_network1, 'models/q_network_4x4x4.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import plot_evaluation_data, plot_valid_actions\n",
    "\n",
    "plot_evaluation_data(learning_agent1)\n",
    "plot_evaluation_data(learning_agent2)\n",
    "\n",
    "plot_valid_actions(learning_agent1)\n",
    "plot_valid_actions(learning_agent2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
